GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 1 processes
----------------------------------------------------------------------------------------------------

You are using a CUDA device ('NVIDIA A30') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mnt/disk1/aiotlab/hieupc/New_CBraMod/BIOT/run_multiclass_supervised.py", line 410, in <module>
[rank0]:     supervised(args)
[rank0]:   File "/mnt/disk1/aiotlab/hieupc/New_CBraMod/BIOT/run_multiclass_supervised.py", line 354, in supervised
[rank0]:     trainer.fit(
[rank0]:   File "/mnt/disk1/aiotlab/envs/hieupcvp/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
[rank0]:     call._call_and_handle_interrupt(
[rank0]:   File "/mnt/disk1/aiotlab/envs/hieupcvp/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 36, in _call_and_handle_interrupt
[rank0]:     return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/disk1/aiotlab/envs/hieupcvp/lib/python3.12/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 88, in launch
[rank0]:     return function(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/mnt/disk1/aiotlab/envs/hieupcvp/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
[rank0]:     self._run(model, ckpt_path=self.ckpt_path)
[rank0]:   File "/mnt/disk1/aiotlab/envs/hieupcvp/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1048, in _run
[rank0]:     self.strategy.setup_environment()
[rank0]:   File "/mnt/disk1/aiotlab/envs/hieupcvp/lib/python3.12/site-packages/pytorch_lightning/strategies/ddp.py", line 153, in setup_environment
[rank0]:     super().setup_environment()
[rank0]:   File "/mnt/disk1/aiotlab/envs/hieupcvp/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 131, in setup_environment
[rank0]:     self.accelerator.setup_device(self.root_device)
[rank0]:   File "/mnt/disk1/aiotlab/envs/hieupcvp/lib/python3.12/site-packages/pytorch_lightning/accelerators/cuda.py", line 44, in setup_device
[rank0]:     torch.cuda.set_device(device)
[rank0]:   File "/mnt/disk1/aiotlab/envs/hieupcvp/lib/python3.12/site-packages/torch/cuda/__init__.py", line 569, in set_device
[rank0]:     torch._C._cuda_setDevice(device)
[rank0]: torch.AcceleratorError: CUDA error: out of memory
[rank0]: CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[rank0]: For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[rank0]: Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
